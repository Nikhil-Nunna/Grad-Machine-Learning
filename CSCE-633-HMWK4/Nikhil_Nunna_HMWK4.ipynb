{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Data Pre-processing\n",
    "\n",
    "#### 1. Read in Loan Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "df = pd.read_csv('loan_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pre-process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop empty rows\n",
    "df.dropna(inplace=True)\n",
    "print(df.head(10))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 different features in this data frame and there are 480 different samples, so the data is stored in a 480 by 13 dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Extract Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature data frame\n",
    "\n",
    "# Remove loan ID since it doesn't help with regression or classification\n",
    "\n",
    "X = df[['Gender','Married','Dependents','Education','Self_Employed','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Credit_History','Property_Area']]\n",
    "# seperate all non-numerical columns\n",
    "\n",
    "X_cat = X.select_dtypes(exclude=['int64', 'float64'])\n",
    "# seperate all numerical columns\n",
    "\n",
    "X_dog = X.select_dtypes(include=['int64', 'float64'])\n",
    "# Transform cateorgical columns to numerical\n",
    "\n",
    "X_cat['Gender'] = X_cat['Gender'].replace({'Female': 0.0, 'Male': 1.0})\n",
    "X_cat['Married'] = X_cat['Married'].replace({'No': 0.0, 'Yes': 1.0})\n",
    "X_cat['Dependents'] = X_cat['Dependents'].replace({'0': 0.0, '1': 1.0, '2': 2.0, '3': 3.0, '3+': 3.0})\n",
    "X_cat['Education'] = X_cat['Education'].replace({'Not Graduate': 0.0, 'Graduate': 1.0,})\n",
    "X_cat['Self_Employed'] = X_cat['Self_Employed'].replace({'No': 0.0, 'Yes': 1.0,})\n",
    "X_cat['Property_Area'] = X_cat['Property_Area'].replace({'Urban': 0.0, 'Rural': 1.0, 'Semiurban': 2.0})\n",
    "# Merge non-numerical and numerical data back together\n",
    "\n",
    "X = pd.concat([X_cat, X_dog], axis=1)\n",
    "print(X)\n",
    "\n",
    "# lable data frame\n",
    "y = df[['Loan_Status']]\n",
    "y['Loan_Status'] = y['Loan_Status'].replace({'N': 0.0, 'Y': 1.0,})\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Extract Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframes to numpy matrices\n",
    "Xnp = np.matrix(X.values,dtype=np.float64)\n",
    "ynp = np.array(y.values,dtype=np.float64)\n",
    "\n",
    "# print(Xnp.shape)\n",
    "# print(ynp.shape)\n",
    "\n",
    "# Define proportions for train, validation, and test sets\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Calculate sizes of each split\n",
    "train_size = int(train_ratio * len(Xnp))\n",
    "val_size = int(val_ratio * len(Xnp))\n",
    "test_size = len(Xnp) - train_size - val_size\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, X_test = Xnp[:train_size], Xnp[train_size:train_size+val_size], Xnp[train_size+val_size:]\n",
    "y_train, y_val, y_test = ynp[:train_size], ynp[train_size:train_size+val_size], ynp[train_size+val_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - Decsion Tree Implementation\n",
    "\n",
    "#### 1. Regression Tree\n",
    "\n",
    "##### The accuracy of the test and validation sets are outputed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        # Index of the feature to split on\n",
    "        self.feature_index = feature_index\n",
    "        # Threshold value for the split\n",
    "        self.threshold = threshold  \n",
    "        # Left child node\n",
    "        self.left = left\n",
    "        # Right child node\n",
    "        self.right = right  \n",
    "        # For leaf nodes: mean value of the target variable\n",
    "        self.value = value\n",
    "\n",
    "class RegressionTree:\n",
    "    def __init__(self, max_depth):\n",
    "        # Initialize the regression tree with maximum depth\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def mean_squared_error(self, y):\n",
    "        # Flatten the y vals\n",
    "        y = y.flatten()\n",
    "        # Calculate the mean squared error of a set of target values\n",
    "        return np.mean((y - np.mean(y))**2)\n",
    "\n",
    "    def splitting_criteria(self, X_column, y):\n",
    "\n",
    "        # Unique values in the feature\n",
    "        thresholds = np.unique(X_column)\n",
    "        # Initialize the best mean squared error\n",
    "        best_mse = float('inf')  \n",
    "        # Initialize the best threshold\n",
    "        best_threshold = None  \n",
    "        for threshold in thresholds:\n",
    "            # Split the data based on the threshold\n",
    "            left_indices = np.where(X_column <= threshold)[0]\n",
    "            right_indices = np.where(X_column > threshold)[0]\n",
    "            # Calculate the mean squared error for the split\n",
    "            left_mse = self.mean_squared_error(y[left_indices])\n",
    "            right_mse = self.mean_squared_error(y[right_indices])\n",
    "            # Calculate the weighted average of the mean squared errors\n",
    "            mse = (len(left_indices) * left_mse + len(right_indices) * right_mse) / len(y)\n",
    "            # Update the best split if the current split has lower mse\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_threshold = threshold\n",
    "        return best_mse, best_threshold\n",
    "\n",
    "    def split(self, X, y):\n",
    "        # Find the best feature to split on and the corresponding threshold\n",
    "        n_samples, n_features = X.shape\n",
    "        # Initialize the best mean squared error\n",
    "        best_mse = float('inf')  \n",
    "        # Initialize the best feature index\n",
    "        best_feature_index = None\n",
    "        # Initialize the best threshold\n",
    "        best_threshold = None  \n",
    "        for feature_index in range(n_features):\n",
    "            # Calculate the splitting criteria for each feature\n",
    "            X_column = (np.asarray(X[:, feature_index]))\n",
    "            mse, threshold = self.splitting_criteria(X_column, y)\n",
    "            # Update the best split if the current split has lower mse\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "        # Split the data based on the best feature and threshold\n",
    "        left_indices = np.where(X[:, best_feature_index] <= best_threshold)[0]\n",
    "        right_indices = np.where(X[:, best_feature_index] > best_threshold)[0]\n",
    "        return best_feature_index, best_threshold, left_indices, right_indices\n",
    "\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        # Recursively build the decision tree\n",
    "        if depth >= self.max_depth or len(np.unique(y)) == 1:\n",
    "            # If the maximum depth is reached or all target values are the same, create a leaf node\n",
    "            return Node(value=np.mean(y))\n",
    "        # Find the best feature to split on and the corresponding threshold\n",
    "        feature_index, threshold, left_indices, right_indices = self.split(X, y)\n",
    "        # Recursively build the left and right subtrees\n",
    "        left = self.build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right = self.build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        # Create a node with the best split\n",
    "        return Node(feature_index, threshold, left, right)\n",
    "\n",
    "    def predict_sample(self, x, node):\n",
    "        # Predict the output for a single sample\n",
    "        if node.value is not None:\n",
    "            # If the node is a leaf node, return the mean value of the target variable\n",
    "            return node.value\n",
    "        # Recursively traverse the tree to find the leaf node for the sample\n",
    "        x = x.flatten()\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self.predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self.predict_sample(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict the output for multiple samples\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            # Predict the output for each sample\n",
    "            prediction = self.predict_sample(np.array(x), self.root)\n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Initialize the regression tree\n",
    "regression_tree = RegressionTree(max_depth=(X_train.shape[1]-7))\n",
    "# Train the Tree\n",
    "regression_tree.root = regression_tree.build_tree(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict target values for validation data\n",
    "predictions_val = regression_tree.predict(X_val)\n",
    "# Update any non 1 or 0 validation prediction to be 1 or 0 since these regression vals can only be 1 or 0\n",
    "predictions_val = np.where(predictions_val > 0, 1, predictions_val)\n",
    "# Calculate Accuracy for validation set\n",
    "print(\"Validation set Accuracy of Regression Tree: \", np.mean(predictions_val == y_val.flatten()))\n",
    "\n",
    "\n",
    "\n",
    "# Predict target values for test data\n",
    "predictions_test = regression_tree.predict(X_test)\n",
    "# Update any non 1 or 0 test prediction to be 1 or 0 since these vals can only be 1 or 0 for loan status\n",
    "predictions_test = np.where(predictions_test > 0, 1, predictions_test)\n",
    "# Create DataFrame with predictions\n",
    "test_results = pd.DataFrame({'Predicted': predictions_test})\n",
    "# Save predictions to CSV file\n",
    "test_results.to_csv('Test_Result_1.csv', index=False)\n",
    "# Calculate Accuracy for test set\n",
    "print(\"Test set Accuracy of Regression Tree: \", np.mean(predictions_test == y_test.flatten()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Classification Tree\n",
    "##### The accuracy of the test and validation sets are outputed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTree:\n",
    "    def __init__(self, max_depth):\n",
    "        # Initialize the regression tree with maximum depth\n",
    "        self.max_depth = max_depth\n",
    "   \n",
    "    def gini_impurity(self, y):\n",
    "        # Flatten the y vals\n",
    "        y = y.flatten().astype(int)\n",
    "        # Check for length of y\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        # Calculate the probablity of the feature, can you bin count cause there are only 2 classes 1 or 0\n",
    "        p = np.bincount(y) / len(y)\n",
    "        # Return the difference of the sum of square of probability\n",
    "        return 1 - np.sum(p ** 2)\n",
    "    \n",
    "    def splitting_criteria(self, X_column, y):\n",
    "\n",
    "        # Unique values in the feature\n",
    "        thresholds = np.unique(X_column)\n",
    "        # Initialize the best mean squared error\n",
    "        best_gini = float('inf')  \n",
    "        # Initialize the best threshold\n",
    "        best_threshold = None  \n",
    "        for threshold in thresholds:\n",
    "            # Split the data based on the threshold\n",
    "            left_indices = np.where(X_column <= threshold)[0]\n",
    "            right_indices = np.where(X_column > threshold)[0]\n",
    "            # Calculate the mean squared error for the split\n",
    "            left_gini = self.gini_impurity(y[left_indices])\n",
    "            right_gini = self.gini_impurity(y[right_indices])\n",
    "            # Calculate the weighted average of the mean squared errors\n",
    "            gini_val = (len(left_indices) * left_gini + len(right_indices) * right_gini) / len(y)\n",
    "            # Update the best split if the current split has lower mse\n",
    "            if gini_val < best_gini:\n",
    "                best_gini = gini_val\n",
    "                best_threshold = threshold\n",
    "        return best_gini, best_threshold\n",
    "\n",
    "    def split(self, X, y):\n",
    "        # Find the best feature to split on and the corresponding threshold\n",
    "        n_samples, n_features = X.shape\n",
    "        # Initialize the best mean squared error\n",
    "        best_gini = float('inf')  \n",
    "        # Initialize the best feature index\n",
    "        best_feature_index = None\n",
    "        # Initialize the best threshold\n",
    "        best_threshold = None  \n",
    "        for feature_index in range(n_features):\n",
    "            # Calculate the splitting criteria for each feature\n",
    "            X_column = (np.asarray(X[:, feature_index]))\n",
    "            gini, threshold = self.splitting_criteria(X_column, y)\n",
    "            # Update the best split if the current split has lower mse\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_feature_index = feature_index\n",
    "                best_threshold = threshold\n",
    "        # Split the data based on the best feature and threshold\n",
    "        left_indices = np.where(X[:, best_feature_index] <= best_threshold)[0]\n",
    "        right_indices = np.where(X[:, best_feature_index] > best_threshold)[0]\n",
    "        return best_feature_index, best_threshold, left_indices, right_indices\n",
    "\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        # Recursively build the decision tree\n",
    "        if depth >= self.max_depth or len(np.unique(y)) == 1:\n",
    "            # If the maximum depth is reached or all target values are the same, create a leaf node\n",
    "            return Node(value=np.mean(y))\n",
    "        # Find the best feature to split on and the corresponding threshold\n",
    "        feature_index, threshold, left_indices, right_indices = self.split(X, y)\n",
    "        # Recursively build the left and right subtrees\n",
    "        left = self.build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right = self.build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        # Create a node with the best split\n",
    "        return Node(feature_index, threshold, left, right)\n",
    "\n",
    "    def predict_sample(self, x, node):\n",
    "        # Predict the output for a single sample\n",
    "        if node.value is not None:\n",
    "            # If the node is a leaf node, return the mean value of the target variable\n",
    "            return node.value\n",
    "        # Recursively traverse the tree to find the leaf node for the sample\n",
    "        x = x.flatten()\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self.predict_sample(x, node.left)\n",
    "        else:\n",
    "            return self.predict_sample(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict the output for multiple samples\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            # Predict the output for each sample\n",
    "            prediction = self.predict_sample(np.array(x), self.root)\n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Initialize the regression tree\n",
    "classification_tree = ClassificationTree(max_depth=(X_train.shape[1]-7))\n",
    "# Train the Tree\n",
    "classification_tree.root = classification_tree.build_tree(X_train, y_train) \n",
    "\n",
    "\n",
    "# Predict target values for validation data\n",
    "predictions_val = classification_tree.predict(X_val)\n",
    "# Update any non 1 or 0 validation prediction to be 1 or 0 since these regression vals can only be 1 or 0\n",
    "predictions_val = np.where(predictions_val > 0, 1, predictions_val)\n",
    "# Calculate Accuracy for validation set\n",
    "print(\"Validation set Accuracy of Classification Tree: \", np.mean(predictions_val == y_val.flatten()))\n",
    "\n",
    "# Predict target values for test data\n",
    "predictions_test = classification_tree.predict(X_test)\n",
    "# Update any non 1 or 0 test prediction to be 1 or 0 since these vals can only be 1 or 0 for loan status\n",
    "predictions_test = np.where(predictions_test > 0, 1, predictions_test)\n",
    "# Create DataFrame with predictions\n",
    "test_results = pd.DataFrame({'Predicted': predictions_test})\n",
    "# Save predictions to CSV file\n",
    "test_results.to_csv('Test_Result_2.csv', index=False)\n",
    "# Calculate Accuracy for test set\n",
    "print(\"Test set Accuracy of Classification Tree: \", np.mean(predictions_test == y_test.flatten()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both models the only tuning done was the adjustmnet of the max depth hyperparameter. I adjusted such that I got the highest possible accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
