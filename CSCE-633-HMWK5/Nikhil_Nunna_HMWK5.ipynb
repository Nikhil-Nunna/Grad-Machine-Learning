{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 5 SVM problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part A\n",
    "\n",
    "Data Pre-Proceing \n",
    "Create a binary label based on the column “Chance of Admit”. Convert any values bigger than the mean to 1 and 0 otherwise.\n",
    "\n",
    "In the following code block I load the data read in the Admission data into a data frame and remove any rows with missing values. I then select the Label column \"Chance of Admit\" and load it into to my 'y' data frame, which I then convert to binary 1 or 0 using the averge of the \"Chance of Admit\" Column as the decsion boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Frame\n",
    "df = pd.read_csv('Admission.csv')\n",
    "\n",
    "# drop empty rows\n",
    "df.dropna(inplace=True)\n",
    "# print first 10 rows and shape\n",
    "print(df.head(10))\n",
    "print(\"Data shape: \", df.shape)\n",
    "\n",
    "# Find mean of Chance of Admit, note the space after admit in the data\n",
    "mean_chance_of_admit = df['Chance of Admit '].mean()\n",
    "print(\"Mean Chance of admit: \", mean_chance_of_admit)\n",
    "\n",
    "# Setup label data frame\n",
    "y = df[['Chance of Admit ']]\n",
    "# If greater than mean chance of admit set to 1 otherwise set to 0\n",
    "y['Chance of Admit '] = np.where(y['Chance of Admit '] > mean_chance_of_admit, 1, 0)\n",
    "print(y.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B\n",
    "\n",
    "Model Initialization: Initialize 4 different SVM models with the following kernels.\n",
    "\n",
    "In the following code block I initialize all of the requested SVM models using scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SVC and LinearSVC from sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# SVM regularization parameter\n",
    "C = 1.0\n",
    "\n",
    "# Initialize SVM models with different kernels\n",
    "svm_linear = SVC(kernel='linear', C=C)\n",
    "linear_svc = LinearSVC(C=C)\n",
    "svm_rbf = SVC(kernel='rbf', C=C)\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part C and D\n",
    "\n",
    "Feature Selection and Model Training: Train each SVM Model above with the following feature combinations to predict admission.\n",
    "\n",
    "Result Visualization: Visualize the decision boundary for each model and for each input combination.\n",
    "\n",
    "In the following code block I get the feature subsets from the main dataframe. I then train the models on each feature subset and the results. Lastly I plot the decsion boundry for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define feature subsets\n",
    "\n",
    "# Subset containing CGPA and SOP columns\n",
    "X_cgpa_sop = df[['CGPA','SOP']]\n",
    "# Subset containing CGPA and GRE Score columns\n",
    "X_cgpa_gre = df[['CGPA', 'GRE Score']]\n",
    "# Subset containing SOP and LOR columns\n",
    "X_sop_lor = df[['SOP', 'LOR ']]\n",
    "# Subset containing LOR and GRE Score columns\n",
    "X_lor_gre = df[['LOR ', 'GRE Score']]\n",
    "\n",
    "X_cgpa_sop.Name = \"GPA and SOP\"\n",
    "X_cgpa_gre.Name = \"GPA and GRE\"\n",
    "X_sop_lor.Name = \"SOP and LOR\"\n",
    "X_lor_gre.Name = \"LOR and GRE\"\n",
    "\n",
    "# Create a list of subsets\n",
    "datasets = [X_cgpa_sop, X_cgpa_gre, X_sop_lor, X_lor_gre]\n",
    "\n",
    "# Convert result dataframe to numpy matrix\n",
    "ynp = np.array(y.values, dtype=np.float64)\n",
    "# Flatten to array\n",
    "ynp = ynp.flatten()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
    "\n",
    "for i, curr_set in enumerate(datasets):\n",
    "    for j, clf in enumerate((svm_linear, linear_svc, svm_rbf, svm_poly)):\n",
    "        # Convert feature dataframe to numpy matrix\n",
    "        Xnp = np.array(curr_set.values, dtype=np.float64)\n",
    "\n",
    "        # Fit SVM model\n",
    "        clf.fit(Xnp, ynp)\n",
    "\n",
    "        # step size in the mesh\n",
    "        h = .02 \n",
    "         \n",
    "        # Define meshgrid for plotting decision boundary\n",
    "    \n",
    "        # calculates the minimum and maximum values of the first feature\n",
    "        x_min, x_max = Xnp[:, 0].min() - 1, Xnp[:, 0].max() + 1\n",
    "        # calculates the minimum and maximum values of the second feature\n",
    "        y_min, y_max = Xnp[:, 1].min() - 1, Xnp[:, 1].max() + 1\n",
    "        # This creates a meshgrid for the decision boundary plot\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "        # predicts the class labels for each point in the meshgrid \n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        # match the shape of the meshgrid\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "\n",
    "        # Swtich subplot\n",
    "        ax = axes[i, j]\n",
    "        # Plot decision boundary\n",
    "        ax.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "        # Plot training points\n",
    "        ax.scatter(Xnp[:, 0], Xnp[:, 1], c=ynp, cmap=plt.cm.coolwarm)\n",
    "        # Set x-axis label\n",
    "        ax.set_xlabel(curr_set.columns.tolist()[0])\n",
    "        # Set y-axis label\n",
    "        ax.set_ylabel(curr_set.columns.tolist()[1])\n",
    "        # Set x-axis limits\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        # Set y-axis limits\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        # Set title\n",
    "        if clf == svm_linear:\n",
    "            ax.set_title(f'Decision Boundary for {curr_set.columns.tolist()[0]} and {curr_set.columns.tolist()[1]} with svm linear')\n",
    "        if clf == linear_svc:\n",
    "            ax.set_title(f'Decision Boundary for {curr_set.columns.tolist()[0]} and {curr_set.columns.tolist()[1]} with linear svc')\n",
    "        if clf == svm_rbf:\n",
    "            ax.set_title(f'Decision Boundary for {curr_set.columns.tolist()[0]} and {curr_set.columns.tolist()[1]} with svm rbf')\n",
    "        if clf == svm_poly:\n",
    "            ax.set_title(f'Decision Boundary for {curr_set.columns.tolist()[0]} and {curr_set.columns.tolist()[1]} with svm poly')\n",
    "\n",
    "# Plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part E\n",
    "\n",
    "Result Analysis: Just by looking at the figures you generated before, answer this question: Which of the feature + kernel combinations gave you the best result?\n",
    "\n",
    "I think the linear svm model with SOP and LOR barely beat out the linear svc model with the same features for the best spot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part F\n",
    "\n",
    "Result Post-processing: Were there any outliers in the data? If yes, please explain how we can use a one-class SVM to detect them\n",
    "\n",
    "Yes, since SVM basically creates a boundary based off the majority of the classification data we can label any falsely classified data as an outlier since it deviates from majority of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
